---
title: "Data transformation: tidy data"
author: "MACSS 30500 <br /> University of Chicago"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      highlightStyle: magula
      highlightLines: true
      highlightLanguage: r
      ratio: 16:9
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# generate CSS file
library(xaringanthemer)
style_duo_accent(
  primary_color = "#011f4b",
  secondary_color = "#bbd6c7",
  inverse_header_color = "#222222",
  black_color = "#222222",
  header_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  text_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  code_font_google = xaringanthemer::google_font("Source Code Pro"),
  base_font_size = "24px",
  code_font_size = "20px",
  # title_slide_background_image = "https://github.com/uc-dataviz/course-notes/raw/main/images/hexsticker.svg",
  # title_slide_background_size = "contain",
  # title_slide_background_position = "top",
  header_h1_font_size = "2rem",
  header_h2_font_size = "1.75rem",
  header_h3_font_size = "1.5rem",
  extra_css = list(
    "h1" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h2" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h3" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    ".tiny" = list("font-size" = "70%"),
    ".small" = list("font-size" = "90%"),
    ".midi" = list("font-size" = "150%"),
    ".tiny .remark-code" = list("font-size" = "70%"),
    ".small .remark-code" = list("font-size" = "90%"),
    ".midi .remark-code" = list("font-size" = "150%"),
    ".large" = list("font-size" = "200%"),
    ".xlarge" = list("font-size" = "600%"),
    ".huge" = list(
      "font-size" = "400%",
      "font-family" = "'Montserrat', sans-serif",
      "font-weight" = "bold"
    ),
    ".hand" = list(
      "font-family" = "'Gochi Hand', cursive",
      "font-size" = "125%"
    ),
    ".task" = list(
      "padding-right" = "10px",
      "padding-left" = "10px",
      "padding-top" = "3px",
      "padding-bottom" = "3px",
      "margin-bottom" = "6px",
      "margin-top" = "6px",
      "border-left" = "solid 5px #F1DE67",
      "background-color" = "#F3D03E"
    ),
    ".pull-left" = list(
      "width" = "49%",
      "float" = "left"
    ),
    ".pull-right" = list(
      "width" = "49%",
      "float" = "right"
    ),
    ".pull-left-wide" = list(
      "width" = "70%",
      "float" = "left"
    ),
    ".pull-right-narrow" = list(
      "width" = "27%",
      "float" = "right"
    ),
    ".pull-left-narrow" = list(
      "width" = "27%",
      "float" = "left"
    ),
    ".pull-right-wide" = list(
      "width" = "70%",
      "float" = "right"
    ),
    ".blue" = list(color = "#2A9BB7"),
    ".purple" = list(color = "#a493ba"),
    ".yellow" = list(color = "#f1de67"),
    ".gray" = list(color = "#222222")
  )
)

source(here::here("R", "slide-opts.R"))
```

```{r pkgs, include = FALSE, cache = FALSE}
library(tidyverse)
library(nycflights13)
library(rcis)
library(knitr)
library(here)

theme_set(theme_minimal(base_size = 16))
```


class: inverse, middle

# Agenda

Two main topics:

* Importing and exporting data in R
* Tidy data in theory & practice


---

class: inverse, middle

# Importing Data into R

---

## Importing CSV files

To load data into R we need **importing functions**. There are a number of them depending on the **type of file** we want to import (see "R for Data Science" Ch. 11).

The most common importing functions read **comma-separated values** files. Two main versions:

- **base-R**: `read.csv()`

- **`readr`**: `read_csv()` -- we use this which is part of `tidyverse`

<!-- `read.csv` is a special case of `read.table`, while `read_csv` is special case of `read_delim`. Look them up to check the differences -- read_csv() is more recent, does not  automatically converts strings into factors, is faster  
-->

---

## `read_csv()`

It takes several arguments, as shown in the  [documentation](https://readr.tidyverse.org/reference/read_delim.html). Most commonly used:

```
read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))
```
--

The `file` argument must specified, the other arguments can be left as default:

```
library(readr)

# load data into my local R Studio
read_csv(file = "/Users/Sabrina Nardin/Desktop/testdata.csv")

# load data into my Workbench 
read_csv(file = "/home/nardin/lecture/testdata.csv")

# another way to load data if you are not sure where it is located
read_csv(file = file.choose())
```

<!--
Make sure the file is located in the given path and you are typing the path correctly. Let's practice!
-->

---

## Practice loading data in R

We are going to create a `testdata.csv` file with four columns (id, name, age, food) with different data types and some missing data:

1. Create the file (you can use Excel). Save it on your desktop with a `csv` extension.

1. Open Workbench: upload the file to the server. Skip this step if you are using R on your machine.

1. Look at your current working directory by typing `getwd()` in the console. That's where R looks at files by default.

1. Load the data into R using the `read_csv()` function. Make sure to specify the correct path. If you do not provide a path, R looks in your working directory:
 * `read_csv("/Users/Sabrina Nardin/Desktop/testdata.csv")` 
 * `read_csv("testdata.csv")`

---

### Changing defaults: examples

Let's modify some of the most common arguments and observe the difference: 

`read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))`

First run the default `read_csv(file = "testdata.csv")`

What do you notice?

<!--
type of column is shown at the top, e.g. id is double, name is char, but so is age, which should not be. Why so? the "na" is interpret as a character rather than missing data and all column values are forced to character.
-->

---

### Modify `col_type`

The default is `read_csv(file, col_types = NULL)`. This code manually sets the column types:

```
# option 1
read_csv(file = "testdata.csv",
         col_types = cols(id = col_integer(),
                          name = col_character(),
                          age = col_integer(),
                          food = col_character()))
# option 2
read_csv("testdata.csv", col_types = ("icic"))
```

What do you notice?

<!-- all columns types have been converted to the datatype we specified. R is also guessing that the na for allan's age is actually missing data and so converts it as such, but we get a warning message; type problems() to see more
-->

---

### Modify `na`

The default is `read_csv(file, na = c("", "NA"))`. This code adds more missing data options:

```
read_csv("testdata.csv", na = c("", "NA", "na"))
```

What do you notice?

<!-- we can enlarge the set of missing data to include everything we want
-->


---

### Modify `col_names`

The default is `read_csv(file, col_names = TRUE)`. This code sets `col_names = FALSE`.

```
read_csv(file = "testdata.csv", col_names = FALSE)

```

What do you notice?

---

### Other file formats

The `readr` package and other packages include several functions to load almost all possible file formats that you might encounter (when given an option though, choose a csv over other formats). 

For example:

* **Comma separated csv** use `read_csv()` from the `readr` package
* **Semi column separated csv** use `read_csv2()`from the `readr` package
* **Tab separated files** use `read_tsv()`from the `readr` package
* **RDS** use `readRDS()` or `read_rds()`
* **Excel** use `read_excel()` from the `readxl` package
* **SAS/SPSS/Stata** use the `haven` package (several functions)

--

Cheat Sheet `readr` and `readxl`:
**Help > Cheat Sheets > Browse Cheat Sheets**

---

### `haven` and SAS

```{r haven-sas}
library(haven)

read_sas(data_file = system.file("examples", "iris.sas7bdat",
  package = "haven"
))
```

---

### `haven` and SPSS

```{r haven-spss}
read_sav(file = system.file("examples", "iris.sav",
  package = "haven"
))
```

---

### `haven` and Stata

```{r haven-stata}
read_dta(file = system.file("examples", "iris.dta",
  package = "haven"
))
```

---

class: inverse, middle

# Exporting Data from R

---

## `write_csv()`

Similar to the `read_csv()` function, there is a `write_csv()` function that **generates csv files** from R data frames.

Documentation: https://readr.tidyverse.org/reference/write_delim.html

```
# import
test <- read_csv("testdata.csv", na = c("", "NA", "na"))

# export
write_csv(test, file = "testdata_cleaned.csv")
```


---

class: inverse, middle

# Tidy data

---

## Tidy data

```{r echo = FALSE, out.width = "70%", fig.alt = "Stylized text providing an overview of Tidy Data. The top reads 'Tidy data is a standard way of mapping the meaning of a dataset to its structure. - Hadley Wickham.' On the left reads 'In tidy data: each variable forms a column; each observation forms a row; each cell is a single measurement.' There is an example table on the lower right with columns ‘id’, ‘name’ and ‘color’ with observations for different cats, illustrating tidy data structure."}

include_graphics(path = "tidydata_1.jpg")
```

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst]

<!-- 

tidy data is a very SPECIFICY way of standardizing info in a dataframe
but it is not the only way ad we are going to see some examples
the opposite of tidy would be messy data or untidy 

the reason why tidy data is popular is because provides a STANDARDIZED form
all packages we have learned so far ggplot, dplyr work with tidy data
which means you can simply load the dataset and start working on it
without reshaping it or cleaning it up (if tidy)

point here: as soon as you get data and you know u want to work on them
within the tidyverse (ggplot, dplyr etc) get them in a tidy format first, 
then focus with the analyses or anything else u want to do!

-->

---

## Tidy data

```{r echo = FALSE, out.width = "70%", fig.alt = "There are two sets of anthropomorphized data tables. The top group of three tables are all rectangular and smiling, with a shared speech bubble reading 'our columns are variables and our rows are observations!'. Text to the left of that group reads 'The standard structure of tidy data means that 'tidy datasets are all alike…' The lower group of four tables are all different shapes, look ragged and concerned, and have different speech bubbles reading (from left to right) 'my column are values and my rows are variables', 'I have variables in columns AND in rows', 'I have multiple variables in a single column', and 'I don’t even KNOW what my deal is.' Next to the frazzled data tables is text '...but every messy dataset is messy in its own way. -Hadley Wickham.'"}

include_graphics(path = "tidydata_2.jpg")
```

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst]

---

## Tidy data

```{r echo = FALSE, out.width = "70%", fig.alt = "On the left is a happy cute fuzzy monster holding a rectangular data frame with a tool that fits the data frame shape. On the workbench behind the monster are other data frames of similar rectangular shape, and neatly arranged tools that also look like they would fit those data frames. The workbench looks uncluttered and tidy. The text above the tidy workbench reads 'When working with tidy data, we can use the same tools in similar ways for different datasets…' On the right is a cute monster looking very frustrated, using duct tape and other tools to haphazardly tie data tables together, each in a different way. The monster is in front of a messy, cluttered workbench. The text above the frustrated monster reads '...but working with untidy data often means reinventing the wheel with one-time approaches that are hard to iterate or reuse.'"}

include_graphics(path = "tidydata_3.jpg")

```

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst]

---

## Tidy data

Most data you will encounter in real life is stored in an untidy format.
To tidy the data:

1. Identify the observations and the variables
1. Put the observations in rows and the variables in columns
1. Make sure that each value has its own cell 

Typical problems:

1. One variable is spread across multiple columns
1. One observation is spread across multiple rows

---

## Common tidying tasks

* Pivoting
    * Longer: makes dataset longer by increasing rows 
    * Wider: makes dataset wider by increasing columns
* Separating
* Uniting

We are going to illustrate these tasks using data from the readings (Chapter 12 R for Data Science). 

Each dataset shows the same values of four variables country, year, population, and cases, but each dataset organises the values in a different way.

---

## Pivot longer

Look at this dataset. Why is it messy/untidy? 

```{r}
library(tidyverse)
table4a
```

--

"Each variable must have its own column": column names should be names of variables. Instead, here they are variables' values (1999 and 2000 are values of the year variable)

"Each observation must have its own row": we have one row for every country, but that's not enough because this is panel data. We should have the country-year pair to define one observation, rather than only country.

---

## Pivot longer

.pull-left[

```{r spread-columns}
table4a
```

]


.pull-right[

```{r pivot-longer}
pivot_longer(
  data = table4a,
  cols = c(`1999`, `2000`),
  names_to = "year",
  values_to = "cases"
)
```

]

<!--
We can reshape and tidy it using `pivot_longer`, which takes four main arguments:
- data: data we are reshaping -- notice we go from a 3by3 to a 6by3
- cols: name of the columns we want to change -- aka columns use to make this pivot; note the use of back ticks!
- names_to column: new column we wish to create from column names
- values_to column: new column we wish to create and fill with values
-->

--

---

## Pivot wider

Look at this dataset. Why is it messy/untidy? 

.pull-left[
```{r}
library(tidyverse)
table2
```

]

--

.pull-right[

"Each variable must have its own column". The current values of the `type`        column are not values but are variables names. 
  
"Each observation must have its own row". Here an observation is a country in a year, but each observation is spread across two rows.

]

---

## Pivot wider

.pull-left[

```{r spread-rows}
table2
```

]

--

.pull-right[

```{r pivot-wider}
pivot_wider(
  data = table2,
  names_from = type,
  values_from = count
)
```

]

---

## Separating

Look at this dataset. Why is it messy/untidy? 

```{r}
table3
```


---

## Separating

.pull-left[

```{r merged-columns}
table3
```

]

--

.pull-right[

```{r separate}
separate(
  data = table3,
  col = rate,
  into = c(
    "cases",
    "population"
  ),
  convert = TRUE
)
```

]


<!-- convert = TRUE bcs the default is FALSE
the original data are coded as chr but we want them as integer; if you do not convert it will leave them as chr
-->

---


## Uniting

Look at this dataset. Why is it messy/untidy? 

```{r}
table5
```

---

## Uniting

.pull-left[

```{r merged-rows}
table5
```

]

--

.pull-right[

```{r unite}
unite(
  data = table5,
  col = "year",
  century, year
)
```

]

---

## Uniting

.pull-left[

```{r ref.label = "merged-rows"}

```

]

.pull-right[

```{r unite-underscore}
unite(
  data = table5,
  col = "year",
  century, year,
  # remove underscore
  sep = ""
)
```

]

---

## Uniting

.pull-left[

```{r ref.label = "merged-rows"}

```

]

.pull-right[

```{r unite-parse}
unite(
  data = table5,
  col = "year",
  century, year,
  # remove underscore
  sep = ""
) %>%
  # store as numeric
  mutate(year = parse_number(year))
```
]

<!--

# Let's get messy!

```{r echo = FALSE, out.width = "50%"}
include_graphics(path = "https://media.giphy.com/media/fCUCbWXe9JONVsJSUd/giphy.gif")
```
-->

---

class: inverse, middle

# Practice tidying data

Download today's in-class exercises from the website


---

## Acknowledgments 

The content of these slides is derived in part from Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.

<!--
```{r compare-speed-small, dependson = "data-gen", message = FALSE, echo = FALSE}
library(microbenchmark)

results_small <- microbenchmark(
  read.csv = read.csv(here("static", "data", "sim-data-small.csv")),
  read_csv = read_csv(here("static", "data", "sim-data-small.csv"))
)
```

```{r compare-speed-small-plot, dependson = "compare-speed-small", message = FALSE, echo = FALSE}
autoplot(results_small) +
  scale_y_log10() +
  labs(
    title = str_c("Number of observations:",
      scales::comma(nrow(read_csv(here("static", "data", "sim-data-small.csv")))),
      sep = " "
    ),
    y = "Time [milliseconds], logged"
  )
```

## `readr` vs. base R

```{r compare-speed-large, dependson = "data-gen", message = FALSE, echo = FALSE}
results_large <- microbenchmark(
  read.csv = read.csv(here("static", "data", "sim-data-large.csv")),
  read_csv = read_csv(here("static", "data", "sim-data-large.csv"))
)
```

```{r compare-speed-large-plot, dependson = "compare-speed-large", message = FALSE, echo = FALSE}
autoplot(results_large) +
  scale_y_log10() +
  labs(
    title = str_c("Number of observations:",
      scales::comma(nrow(read_csv(here("static", "data", "sim-data-large.csv")))),
      sep = " "
    ),
    y = "Time [milliseconds], logged"
  )
```
-->