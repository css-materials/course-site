<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Data transformation: tidy data</title>
    <meta charset="utf-8" />
    <meta name="author" content="MACSS 30500   University of Chicago" />
    <script src="index_files/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Data transformation: tidy data
]
.author[
### MACSS 30500 <br /> University of Chicago
]

---







class: inverse, middle

# Agenda

Two main topics:

* Importing and exporting data in R
* Tidy data in theory &amp; practice


---

class: inverse, middle

# Importing Data into R

---

## Importing CSV files

To load data into R we need **importing functions**. There are a number of them depending on the **type of file** we want to import (see "R for Data Science" Ch. 11).

The most common importing functions read **comma-separated values** files. Two main versions:

- **base-R**: `read.csv()`

- **`readr`**: `read_csv()` -- we use this which is part of `tidyverse`

&lt;!-- `read.csv` is a special case of `read.table`, while `read_csv` is special case of `read_delim`. Look them up to check the differences -- read_csv() is more recent, does not  automatically converts strings into factors, is faster  
--&gt;

---

## `read_csv()`

It takes several arguments, as shown in the  [documentation](https://readr.tidyverse.org/reference/read_delim.html). Most commonly used:

```
read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))
```
--

The `file` argument must specified, the other arguments can be left as default:

```
library(readr)

# load data into my local R Studio
read_csv(file = "/Users/Sabrina Nardin/Desktop/testdata.csv")

# load data into my Workbench 
read_csv(file = "/home/nardin/lecture/testdata.csv")

# another way to load data if you are not sure where it is located
read_csv(file = file.choose())
```

&lt;!--
Make sure the file is located in the given path and you are typing the path correctly. Let's practice!
--&gt;

---

## Practice loading data in R

We are going to create a `testdata.csv` file with four columns (id, name, age, food) with different data types and some missing data:

1. Create the file (you can use Excel). Save it on your desktop with a `csv` extension.

1. Open Workbench: upload the file to the server. Skip this step if you are using R on your machine.

1. Look at your current working directory by typing `getwd()` in the console. That's where R looks at files by default.

1. Load the data into R using the `read_csv()` function. Make sure to specify the correct path. If you do not provide a path, R looks in your working directory:
 * `read_csv("/Users/Sabrina Nardin/Desktop/testdata.csv")` 
 * `read_csv("testdata.csv")`

---

### Changing defaults: examples

Let's modify some of the most common arguments and observe the difference: 

`read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))`

First run the default `read_csv(file = "testdata.csv")`

What do you notice?

&lt;!--
type of column is shown at the top, e.g. id is double, name is char, but so is age, which should not be. Why so? the "na" is interpret as a character rather than missing data and all column values are forced to character.
--&gt;

---

### Modify `col_type`

The default is `read_csv(file, col_types = NULL)`. This code manually sets the column types:

```
# option 1
read_csv(file = "testdata.csv",
         col_types = cols(id = col_integer(),
                          name = col_character(),
                          age = col_integer(),
                          food = col_character()))
# option 2
read_csv("testdata.csv", col_types = ("icic"))
```

What do you notice?

&lt;!-- all columns types have been converted to the datatype we specified. R is also guessing that the na for allan's age is actually missing data and so converts it as such, but we get a warning message; type problems() to see more
--&gt;

---

### Modify `na`

The default is `read_csv(file, na = c("", "NA"))`. This code adds more missing data options:

```
read_csv("testdata.csv", na = c("", "NA", "na"))
```

What do you notice?

&lt;!-- we can enlarge the set of missing data to include everything we want
--&gt;


---

### Modify `col_names`

The default is `read_csv(file, col_names = TRUE)`. This code sets `col_names = FALSE`.

```
read_csv(file = "testdata.csv", col_names = FALSE)

```

What do you notice?

---

### Other file formats

The `readr` package and other packages include several functions to load almost all possible file formats that you might encounter (when given an option though, choose a csv over other formats). 

For example:

* **Comma separated csv** use `read_csv()` from the `readr` package
* **Semi column separated csv** use `read_csv2()`from the `readr` package
* **Tab separated files** use `read_tsv()`from the `readr` package
* **RDS** use `readRDS()` or `read_rds()`
* **Excel** use `read_excel()` from the `readxl` package
* **SAS/SPSS/Stata** use the `haven` package (several functions)

--

Cheat Sheet `readr` and `readxl`:
**Help &gt; Cheat Sheets &gt; Browse Cheat Sheets**

---

### `haven` and SAS


```r
library(haven)

read_sas(data_file = system.file("examples", "iris.sas7bdat",
  package = "haven"
))
```

```
## # A tibble: 150 x 5
##    Sepal_Length Sepal_Width Petal_Length Petal_Width Species
##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
##  1          5.1         3.5          1.4         0.2 setosa 
##  2          4.9         3            1.4         0.2 setosa 
##  3          4.7         3.2          1.3         0.2 setosa 
##  4          4.6         3.1          1.5         0.2 setosa 
##  5          5           3.6          1.4         0.2 setosa 
##  6          5.4         3.9          1.7         0.4 setosa 
##  7          4.6         3.4          1.4         0.3 setosa 
##  8          5           3.4          1.5         0.2 setosa 
##  9          4.4         2.9          1.4         0.2 setosa 
## 10          4.9         3.1          1.5         0.1 setosa 
## # ... with 140 more rows
```

---

### `haven` and SPSS


```r
read_sav(file = system.file("examples", "iris.sav",
  package = "haven"
))
```

```
## # A tibble: 150 x 5
##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species   
##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl+lbl&gt; 
##  1          5.1         3.5          1.4         0.2 1 [setosa]
##  2          4.9         3            1.4         0.2 1 [setosa]
##  3          4.7         3.2          1.3         0.2 1 [setosa]
##  4          4.6         3.1          1.5         0.2 1 [setosa]
##  5          5           3.6          1.4         0.2 1 [setosa]
##  6          5.4         3.9          1.7         0.4 1 [setosa]
##  7          4.6         3.4          1.4         0.3 1 [setosa]
##  8          5           3.4          1.5         0.2 1 [setosa]
##  9          4.4         2.9          1.4         0.2 1 [setosa]
## 10          4.9         3.1          1.5         0.1 1 [setosa]
## # ... with 140 more rows
```

---

### `haven` and Stata


```r
read_dta(file = system.file("examples", "iris.dta",
  package = "haven"
))
```

```
## # A tibble: 150 x 5
##    sepallength sepalwidth petallength petalwidth species
##          &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  
##  1        5.10       3.5         1.40      0.200 setosa 
##  2        4.90       3           1.40      0.200 setosa 
##  3        4.70       3.20        1.30      0.200 setosa 
##  4        4.60       3.10        1.5       0.200 setosa 
##  5        5          3.60        1.40      0.200 setosa 
##  6        5.40       3.90        1.70      0.400 setosa 
##  7        4.60       3.40        1.40      0.300 setosa 
##  8        5          3.40        1.5       0.200 setosa 
##  9        4.40       2.90        1.40      0.200 setosa 
## 10        4.90       3.10        1.5       0.100 setosa 
## # ... with 140 more rows
```

---

class: inverse, middle

# Exporting Data from R

---

## `write_csv()`

Similar to the `read_csv()` function, there is a `write_csv()` function that **generates csv files** from R data frames.

Documentation: https://readr.tidyverse.org/reference/write_delim.html

```
# import
test &lt;- read_csv("testdata.csv", na = c("", "NA", "na"))

# export
write_csv(test, file = "testdata_cleaned.csv")
```


---

class: inverse, middle

# Tidy data

---

## Tidy data

&lt;img src="tidydata_1.jpg" alt="Stylized text providing an overview of Tidy Data. The top reads 'Tidy data is a standard way of mapping the meaning of a dataset to its structure. - Hadley Wickham.' On the left reads 'In tidy data: each variable forms a column; each observation forms a row; each cell is a single measurement.' There is an example table on the lower right with columns ‘id’, ‘name’ and ‘color’ with observations for different cats, illustrating tidy data structure." width="70%" style="display: block; margin: auto;" /&gt;

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst]

&lt;!-- 

tidy data is a very SPECIFICY way of standardizing info in a dataframe
but it is not the only way ad we are going to see some examples
the opposite of tidy would be messy data or untidy 

the reason why tidy data is popular is because provides a STANDARDIZED form
all packages we have learned so far ggplot, dplyr work with tidy data
which means you can simply load the dataset and start working on it
without reshaping it or cleaning it up (if tidy)

point here: as soon as you get data and you know u want to work on them
within the tidyverse (ggplot, dplyr etc) get them in a tidy format first, 
then focus with the analyses or anything else u want to do!

--&gt;

---

## Tidy data

&lt;img src="tidydata_2.jpg" alt="There are two sets of anthropomorphized data tables. The top group of three tables are all rectangular and smiling, with a shared speech bubble reading 'our columns are variables and our rows are observations!'. Text to the left of that group reads 'The standard structure of tidy data means that 'tidy datasets are all alike…' The lower group of four tables are all different shapes, look ragged and concerned, and have different speech bubbles reading (from left to right) 'my column are values and my rows are variables', 'I have variables in columns AND in rows', 'I have multiple variables in a single column', and 'I don’t even KNOW what my deal is.' Next to the frazzled data tables is text '...but every messy dataset is messy in its own way. -Hadley Wickham.'" width="70%" style="display: block; margin: auto;" /&gt;

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst]

---

## Tidy data

&lt;img src="tidydata_3.jpg" alt="On the left is a happy cute fuzzy monster holding a rectangular data frame with a tool that fits the data frame shape. On the workbench behind the monster are other data frames of similar rectangular shape, and neatly arranged tools that also look like they would fit those data frames. The workbench looks uncluttered and tidy. The text above the tidy workbench reads 'When working with tidy data, we can use the same tools in similar ways for different datasets…' On the right is a cute monster looking very frustrated, using duct tape and other tools to haphazardly tie data tables together, each in a different way. The monster is in front of a messy, cluttered workbench. The text above the frustrated monster reads '...but working with untidy data often means reinventing the wheel with one-time approaches that are hard to iterate or reuse.'" width="70%" style="display: block; margin: auto;" /&gt;

.footnote[Illustrations from the [Openscapes](https://www.openscapes.org/) blog [*Tidy Data for reproducibility, efficiency, and collaboration*](https://www.openscapes.org/blog/2020/10/12/tidy-data/) by Julia Lowndes and Allison Horst]

---

## Tidy data

Most data you will encounter in real life is stored in an untidy format.
To tidy the data:

1. Identify the observations and the variables
1. Put the observations in rows and the variables in columns
1. Make sure that each value has its own cell 

Typical problems:

1. One variable is spread across multiple columns
1. One observation is spread across multiple rows

---

## Common tidying tasks

* Pivoting
    * Longer: makes dataset longer by increasing rows 
    * Wider: makes dataset wider by increasing columns
* Separating
* Uniting

We are going to illustrate these tasks using data from the readings (Chapter 12 R for Data Science). 

Each dataset shows the same values of four variables country, year, population, and cases, but each dataset organises the values in a different way.

---

## Pivot longer

Look at this dataset. Why is it messy/untidy? 


```r
library(tidyverse)
table4a
```

```
## # A tibble: 3 x 3
##   country     `1999` `2000`
## * &lt;chr&gt;        &lt;int&gt;  &lt;int&gt;
## 1 Afghanistan    745   2666
## 2 Brazil       37737  80488
## 3 China       212258 213766
```

--

"Each variable must have its own column": column names should be names of variables. Instead, here they are variables' values (1999 and 2000 are values of the year variable)

"Each observation must have its own row": we have one row for every country, but that's not enough because this is panel data. We should have the country-year pair to define one observation, rather than only country.

---

## Pivot longer

.pull-left[


```r
table4a
```

```
## # A tibble: 3 x 3
##   country     `1999` `2000`
## * &lt;chr&gt;        &lt;int&gt;  &lt;int&gt;
## 1 Afghanistan    745   2666
## 2 Brazil       37737  80488
## 3 China       212258 213766
```

]


.pull-right[


```r
pivot_longer(
  data = table4a,
  cols = c(`1999`, `2000`),
  names_to = "year",
  values_to = "cases"
)
```

```
## # A tibble: 6 x 3
##   country     year   cases
##   &lt;chr&gt;       &lt;chr&gt;  &lt;int&gt;
## 1 Afghanistan 1999     745
## 2 Afghanistan 2000    2666
## 3 Brazil      1999   37737
## 4 Brazil      2000   80488
## 5 China       1999  212258
## 6 China       2000  213766
```

]

&lt;!--
We can reshape and tidy it using `pivot_longer`, which takes four main arguments:
- data: data we are reshaping -- notice we go from a 3by3 to a 6by3
- cols: name of the columns we want to change -- aka columns use to make this pivot; note the use of back ticks!
- names_to column: new column we wish to create from column names
- values_to column: new column we wish to create and fill with values
--&gt;

--

---

## Pivot wider

Look at this dataset. Why is it messy/untidy? 

.pull-left[

```r
library(tidyverse)
table2
```

```
## # A tibble: 12 x 4
##    country      year type            count
##    &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;           &lt;int&gt;
##  1 Afghanistan  1999 cases             745
##  2 Afghanistan  1999 population   19987071
##  3 Afghanistan  2000 cases            2666
##  4 Afghanistan  2000 population   20595360
##  5 Brazil       1999 cases           37737
##  6 Brazil       1999 population  172006362
##  7 Brazil       2000 cases           80488
##  8 Brazil       2000 population  174504898
##  9 China        1999 cases          212258
## 10 China        1999 population 1272915272
## 11 China        2000 cases          213766
## 12 China        2000 population 1280428583
```

]

--

.pull-right[

"Each variable must have its own column". The current values of the `type`        column are not values but are variables names. 
  
"Each observation must have its own row". Here an observation is a country in a year, but each observation is spread across two rows.

]

---

## Pivot wider

.pull-left[


```r
table2
```

```
## # A tibble: 12 x 4
##    country      year type            count
##    &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;           &lt;int&gt;
##  1 Afghanistan  1999 cases             745
##  2 Afghanistan  1999 population   19987071
##  3 Afghanistan  2000 cases            2666
##  4 Afghanistan  2000 population   20595360
##  5 Brazil       1999 cases           37737
##  6 Brazil       1999 population  172006362
##  7 Brazil       2000 cases           80488
##  8 Brazil       2000 population  174504898
##  9 China        1999 cases          212258
## 10 China        1999 population 1272915272
## 11 China        2000 cases          213766
## 12 China        2000 population 1280428583
```

]

--

.pull-right[


```r
pivot_wider(
  data = table2,
  names_from = type,
  values_from = count
)
```

```
## # A tibble: 6 x 4
##   country      year  cases population
##   &lt;chr&gt;       &lt;int&gt;  &lt;int&gt;      &lt;int&gt;
## 1 Afghanistan  1999    745   19987071
## 2 Afghanistan  2000   2666   20595360
## 3 Brazil       1999  37737  172006362
## 4 Brazil       2000  80488  174504898
## 5 China        1999 212258 1272915272
## 6 China        2000 213766 1280428583
```

]

---

## Separating

Look at this dataset. Why is it messy/untidy? 


```r
table3
```

```
## # A tibble: 6 x 3
##   country      year rate             
## * &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;            
## 1 Afghanistan  1999 745/19987071     
## 2 Afghanistan  2000 2666/20595360    
## 3 Brazil       1999 37737/172006362  
## 4 Brazil       2000 80488/174504898  
## 5 China        1999 212258/1272915272
## 6 China        2000 213766/1280428583
```


---

## Separating

.pull-left[


```r
table3
```

```
## # A tibble: 6 x 3
##   country      year rate             
## * &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;            
## 1 Afghanistan  1999 745/19987071     
## 2 Afghanistan  2000 2666/20595360    
## 3 Brazil       1999 37737/172006362  
## 4 Brazil       2000 80488/174504898  
## 5 China        1999 212258/1272915272
## 6 China        2000 213766/1280428583
```

]

--

.pull-right[


```r
separate(
  data = table3,
  col = rate,
  into = c(
    "cases",
    "population"
  ),
  convert = TRUE
)
```

```
## # A tibble: 6 x 4
##   country      year  cases population
##   &lt;chr&gt;       &lt;int&gt;  &lt;int&gt;      &lt;int&gt;
## 1 Afghanistan  1999    745   19987071
## 2 Afghanistan  2000   2666   20595360
## 3 Brazil       1999  37737  172006362
## 4 Brazil       2000  80488  174504898
## 5 China        1999 212258 1272915272
## 6 China        2000 213766 1280428583
```

]


&lt;!-- convert = TRUE bcs the default is FALSE
the original data are coded as chr but we want them as integer; if you do not convert it will leave them as chr
--&gt;

---


## Uniting

Look at this dataset. Why is it messy/untidy? 


```r
table5
```

```
## # A tibble: 6 x 4
##   country     century year  rate             
## * &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;            
## 1 Afghanistan 19      99    745/19987071     
## 2 Afghanistan 20      00    2666/20595360    
## 3 Brazil      19      99    37737/172006362  
## 4 Brazil      20      00    80488/174504898  
## 5 China       19      99    212258/1272915272
## 6 China       20      00    213766/1280428583
```

---

## Uniting

.pull-left[


```r
table5
```

```
## # A tibble: 6 x 4
##   country     century year  rate             
## * &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;            
## 1 Afghanistan 19      99    745/19987071     
## 2 Afghanistan 20      00    2666/20595360    
## 3 Brazil      19      99    37737/172006362  
## 4 Brazil      20      00    80488/174504898  
## 5 China       19      99    212258/1272915272
## 6 China       20      00    213766/1280428583
```

]

--

.pull-right[


```r
unite(
  data = table5,
  col = "year",
  century, year
)
```

```
## # A tibble: 6 x 3
##   country     year  rate             
##   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;            
## 1 Afghanistan 19_99 745/19987071     
## 2 Afghanistan 20_00 2666/20595360    
## 3 Brazil      19_99 37737/172006362  
## 4 Brazil      20_00 80488/174504898  
## 5 China       19_99 212258/1272915272
## 6 China       20_00 213766/1280428583
```

]

---

## Uniting

.pull-left[


```r
table5
```

```
## # A tibble: 6 x 4
##   country     century year  rate             
## * &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;            
## 1 Afghanistan 19      99    745/19987071     
## 2 Afghanistan 20      00    2666/20595360    
## 3 Brazil      19      99    37737/172006362  
## 4 Brazil      20      00    80488/174504898  
## 5 China       19      99    212258/1272915272
## 6 China       20      00    213766/1280428583
```

]

.pull-right[


```r
unite(
  data = table5,
  col = "year",
  century, year,
  # remove underscore
  sep = ""
)
```

```
## # A tibble: 6 x 3
##   country     year  rate             
##   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;            
## 1 Afghanistan 1999  745/19987071     
## 2 Afghanistan 2000  2666/20595360    
## 3 Brazil      1999  37737/172006362  
## 4 Brazil      2000  80488/174504898  
## 5 China       1999  212258/1272915272
## 6 China       2000  213766/1280428583
```

]

---

## Uniting

.pull-left[


```r
table5
```

```
## # A tibble: 6 x 4
##   country     century year  rate             
## * &lt;chr&gt;       &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;            
## 1 Afghanistan 19      99    745/19987071     
## 2 Afghanistan 20      00    2666/20595360    
## 3 Brazil      19      99    37737/172006362  
## 4 Brazil      20      00    80488/174504898  
## 5 China       19      99    212258/1272915272
## 6 China       20      00    213766/1280428583
```

]

.pull-right[


```r
unite(
  data = table5,
  col = "year",
  century, year,
  # remove underscore
  sep = ""
) %&gt;%
  # store as numeric
  mutate(year = parse_number(year))
```

```
## # A tibble: 6 x 3
##   country      year rate             
##   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            
## 1 Afghanistan  1999 745/19987071     
## 2 Afghanistan  2000 2666/20595360    
## 3 Brazil       1999 37737/172006362  
## 4 Brazil       2000 80488/174504898  
## 5 China        1999 212258/1272915272
## 6 China        2000 213766/1280428583
```
]

&lt;!--

# Let's get messy!

&lt;img src="https://media.giphy.com/media/fCUCbWXe9JONVsJSUd/giphy.gif" width="50%" style="display: block; margin: auto;" /&gt;
--&gt;

---

class: inverse, middle

# Practice tidying data

Download today's in-class exercises from the website


---

## Acknowledgments 

The content of these slides is derived in part from Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.

&lt;!--


&lt;img src="index_files/figure-html/compare-speed-small-plot-1.png" width="80%" style="display: block; margin: auto;" /&gt;

## `readr` vs. base R



&lt;img src="index_files/figure-html/compare-speed-large-plot-1.png" width="80%" style="display: block; margin: auto;" /&gt;
--&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
