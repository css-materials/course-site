---
title: "Exploratory Data Analysis"
author: "MACSS 30500 <br /> University of Chicago"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      highlightStyle: magula
      highlightLines: true
      highlightLanguage: r
      ratio: 16:9
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# generate CSS file
library(xaringanthemer)
style_duo_accent(
  primary_color = "#011f4b",
  secondary_color = "#bbd6c7",
  inverse_header_color = "#222222",
  black_color = "#222222",
  header_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  text_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  code_font_google = xaringanthemer::google_font("Source Code Pro"),
  base_font_size = "24px",
  code_font_size = "20px",
  # title_slide_background_image = "https://github.com/uc-dataviz/course-notes/raw/main/images/hexsticker.svg",
  # title_slide_background_size = "contain",
  # title_slide_background_position = "top",
  header_h1_font_size = "2rem",
  header_h2_font_size = "1.75rem",
  header_h3_font_size = "1.5rem",
  extra_css = list(
    "h1" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h2" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h3" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    ".tiny" = list("font-size" = "70%"),
    ".small" = list("font-size" = "90%"),
    ".midi" = list("font-size" = "150%"),
    ".tiny .remark-code" = list("font-size" = "70%"),
    ".small .remark-code" = list("font-size" = "90%"),
    ".midi .remark-code" = list("font-size" = "150%"),
    ".large" = list("font-size" = "200%"),
    ".xlarge" = list("font-size" = "600%"),
    ".huge" = list(
      "font-size" = "400%",
      "font-family" = "'Montserrat', sans-serif",
      "font-weight" = "bold"
    ),
    ".hand" = list(
      "font-family" = "'Gochi Hand', cursive",
      "font-size" = "125%"
    ),
    ".task" = list(
      "padding-right" = "10px",
      "padding-left" = "10px",
      "padding-top" = "3px",
      "padding-bottom" = "3px",
      "margin-bottom" = "6px",
      "margin-top" = "6px",
      "border-left" = "solid 5px #F1DE67",
      "background-color" = "#F3D03E"
    ),
    ".pull-left" = list(
      "width" = "49%",
      "float" = "left"
    ),
    ".pull-right" = list(
      "width" = "49%",
      "float" = "right"
    ),
    ".pull-left-wide" = list(
      "width" = "70%",
      "float" = "left"
    ),
    ".pull-right-narrow" = list(
      "width" = "27%",
      "float" = "right"
    ),
    ".pull-left-narrow" = list(
      "width" = "27%",
      "float" = "left"
    ),
    ".pull-right-wide" = list(
      "width" = "70%",
      "float" = "right"
    ),
    ".blue" = list(color = "#2A9BB7"),
    ".purple" = list(color = "#a493ba"),
    ".yellow" = list(color = "#f1de67"),
    ".gray" = list(color = "#222222")
  )
)

source(here::here("R", "slide-opts.R"))

# enable panelsets and default theme
xaringanExtra::use_panelset()
```

```{r pkgs, include = FALSE, cache = FALSE}
library(tidyverse)
library(palmerpenguins)
library(rcis)
library(knitr)
library(patchwork)
library(flipbookr)

set.seed(1234)
theme_set(theme_gray(base_size = 16))
```

class: inverse, middle

# Exploratory Data Analysis

---

## Definition of Exploratory Data Analysis (EDA)

**All set of initial investigations in order to get a sense of your data and generate questions**: 
+ discovering patterns 
+ spot anomalies (outliers)
+ formulate and refine questions 
+ check initial hypotheses before formally testing them

--

Exploratory Data Analysis (EDA):
* relies on **visualizations** and frequently goes together with **descriptive statistics**
* is different from **Explanatory or Confirmatory Data Analysis** 

---

## Exploratory Data Analysis as iterative cycle

Chapter 7 of R for Data Science defines EDA as an iterative process:

1. Generate questions about your data
1. Search for answers in the data by transforming, visualizing, and modeling the data
1. Use what you learn to refine your questions and/or generate new questions
1. Repeat until necessary

--

EDA is a **creative process**: it is not an exact science. It requires knowledge of your data and a lot of time. At the most basic level, it involves answering two questions:

1. What type of **variation** occurs within my variables?
2. What type of **covariation** occurs between my variables?


---

## How to perform Exploratory Data Analysis?

EDA relies on:
- **descriptive stats** such as measures of central tendency (mean, mode, median) and of dispersion (variance, standard deviation)
- **visualization tools** such box plots, histograms, bar charts, and scatter plots 

--

We focus on visualizations, and especially on:
- *Variation* that is how values within a single variable vary (univariate analysis)
- *Covariation* that how values of two variables co-vary (bivariate analysis)

--

> Visualizations are employed in both Exploratory and Confirmatory Data Analysis, but their use is different. 

<!--
In Exploratory Analysis you might generate 100 or even 1000 graphs, but not all of them will be useful for your research. In Confirmatory Analysis, you generate only a few graphs and each graph is well refined.
-->

---

class: inverse, middle

# Exploratory VS Confirmatory Data Analysis

---

## Comparing Exploratory and Confirmatory plots

```{r}
library(palmerpenguins)
data("penguins")

head(penguins)
```

We want build a plot of two continuous variables: penguins body mass (in grams) and penguins flipper length (in millimeters)

---

```{r penguins-eda, include = FALSE}
ggplot(
  data = penguins,
  mapping = aes(
    x = body_mass_g,
    y = flipper_length_mm
  )
) +
  geom_point() +
  geom_smooth()
```

`r chunk_reveal(chunk_name = "penguins-eda", break_type = "auto", title = "## Exploratory plot")`

Simple exploratory plot. What does this graph tell us?

--

Pros: minimum code, easy to replicate, good for your internal use
Cons: not well refined, not good for publication or external audience

How can we improve this graph?

---

```{r penguins-final, include = FALSE}
ggplot(
  data = penguins,
  mapping = aes(
    x = body_mass_g,
    y = flipper_length_mm
  )
) +
  geom_point(alpha = .1) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Relationship between body mass and\nflipper length of a penguin",
    subtitle = "Sample of 344 penguins",
    x = "Body mass (g)",
    y = "Flipper length (mm)"
  ) +
  theme_xaringan(
    title_font_size = 18,
    text_font_size = 16
  )
```

`r chunk_reveal(chunk_name = "penguins-final", break_type = "auto", title = "## Confirmatory plot")`

Plot for confirmatory purposes. It requires more code. Good for a final report, class presentation, paper, etc. but not necessary for exploratory purposes.


```{r include = FALSE}
# restore default colors
theme_xaringan_restore_defaults()
```

---

class: inverse, middle

# EDA with the `scorecard` dataset

### Data on every four-year college university in the U.S.
The Department of Education collects annual statistics on colleges and universities in the United States. We are going to look at a subset of this data from 2018-19.

---

## `scorecard`

```{r}
library(rcis)
data("scorecard")
glimpse(scorecard)
```

---

## Types of visualization we can perform:

#### *Variation* -- how values within a single variable vary (univariate analysis)
  
* continuous variable: histogram
* categorical variable: bar chart


#### *Covariation* -- how values of two variables co-vary (bivariate analysis)

* continuous variables: scatter plot
* categorical variables: compute count for each, then visualize
* categorical and continuous variables: box plot

---

class: inverse, middle

# Variation: univariate analysis

---

```{r histogram, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = cost)
) +
  geom_histogram()
```

`r chunk_reveal(chunk_name = "histogram", title = "## Histogram")`

HISTOGRAM: for **continuous variables** (here cost). It splits the input variable into n sets of equal width and does a frequency count within each set.

--

What does this histogram tell us?

--

Follow up questions we might ask: Why do we have these different picks? Who are the outliers?

---

```{r histogram-bins, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = cost)
) +
  geom_histogram(bins = 50) + #ROTATE
  geom_histogram(bins = 30) + #ROTATE
  geom_histogram(bins = 10) #ROTATE
```

`r chunk_reveal(chunk_name = "histogram-bins", break_type = "rotate", title = "## Histogram")`

Bins: each bar is a bin and represents one interval or set of data; `bins` control the size of each bar. In these examples, we divided the data into 50, 30 (default), or 10 equally sized bars.

---

```{r barplot, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = type)
) +
  geom_bar()
```

`r chunk_reveal(chunk_name = "barplot",  title = "## Bar chart")`

BAR CHART: for **categorical variables** (here type). It takes each category of the variable and automatically applies a frequency count to aggregate the data by variable. 

---

## Bar chart 

```{r barplot2, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = type)
) +
  geom_bar()
```

The default stats for `geom_bar()` is `count`. See [documentation](https://ggplot2.tidyverse.org/reference/geom_bar.html) for more info.

It means that under the hood `geom_bar()` performs the equivalent of the following:

```{r}
scorecard %>%
  count(type)
```

Unless we explicitly tell `geom_bar()` not to do so with `geom_bar(stats = "identity")`

---

## Reorder factor levels in a bar chart

.panelset[
.panel[.panel-name[Not Ordered]


```{r not-ordered, echo = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = type)
) +
  geom_bar()
```

]

.panel[.panel-name[Ordered]

```{r reordered, echo = FALSE}
count_type <- scorecard %>%
  count(type)

ggplot(count_type,
       mapping = aes(x = reorder(type, desc(n)), 
                     y = n)) +
       geom_bar(stat = "identity")
```

]
]

---

## Reorder factor levels in a bar chart

The most straightforward approach to reorder the levels of a categorical variables is with dplyr and ggplot combined:

```
# calculate count for variable of interest and save in new dataframe
count_type <- scorecard %>%
  count(type)

# use the new dataframe to create the graph
ggplot(count_type,
       mapping = aes(x = reorder(type, desc(n)), 
                     y = n)) +
       geom_bar(stat = "identity")
```

--

```
# same results in one step
scorecard %>%
  count(type) %>%
  ggplot(count_type,
         mapping = aes(x = reorder(type, desc(n)), 
                       y = n)) +
  geom_bar(stat = "identity")
```


---

## Reorder factor levels in a bar chart

[`fct_relevel()`](https://forcats.tidyverse.org/reference/fct_relevel.html): allows to reorder factor levels by hand

```
scorecard %>%
  mutate(
  type = fct_relevel(.f = type, 
                    levels = "Private, nonprofit", "Public", "Private, for-profit" )) %>%
  ggplot(
    mapping = aes(x = type)) +
    geom_bar()
```

[`fct_infreq()`](https://forcats.tidyverse.org/reference/fct_inorder.html): reorders factor levels by the number of obs. with each level (e.g., by frequency)

```
scorecard %>%
  mutate(type = fct_infreq(type)) %>%
  ggplot(
    mapping = aes(x = type)) +
  geom_bar()
```

---

## Other types of univariate and bivariate graphs

See the Visualization cheat sheet! 

Help > Cheat Sheets > Data Visualization with ggplot2

---

class: inverse, middle

# Covariation: bivariate analysis

---

## Covariation

1. Two-dimensional graphs
1. Multiple window plots
1. Utilizing additional channels

---

```{r boxplot, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(
    x = type,
    y = cost
  )
) +
  geom_boxplot()
```

`r chunk_reveal(chunk_name = "boxplot", title = "## Box plot")`

BOX PLOT: looks at the relationship between a **continuous variable** (here cost) and a  **categorical variable** (here type). It summarizes the continuous variable distribution across each of the categorical variables.

--

What does this box plot tell us?

<!-- median is the line in the middle, the middle value 
Here we see that on average, public universities are the least expensive, followed by private for-profit institutions. I was somewhat surprised by this since for-profit institutions by definition seek to generate a profit, so wouldn't they be the most expensive? But perhaps this makes sense, because they have to attract students so need to offer a better financial value than competing nonprofit or public institutions. Is there a better explanation for these differences? Another question you could explore after viewing this visualization.
-->

---

## Box plot

```{r echo = FALSE}
include_graphics(path = "https://d33wubrfki0l68.cloudfront.net/153b9af53b33918353fda9b691ded68cd7f62f51/5b616/images/eda-boxplot.png")
```

.footnote[Source of image: R for Data Science Chapter 7]


---

```{r scatterplot, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(
    x = cost,
    y = netcost
  )
) +
  geom_point()
```

`r chunk_reveal(chunk_name = "scatterplot", title = "## Scatterplot")`

SCATTERPLOT: looks at the relationship between two **continuous variables** (here cost and netcost). 


--

What does this scatterplot tell us?

<!--

As the advertised price increases, the net cost also increases though with significant variation. Some schools have a much lower net cost than their advertised price.

No clear alignment on diagonal, net costs tend to be lower than adv costs for several schools, especially as the adv costs increase; in most universities the average student pay less than the adv costs. It is a 2d plot bcs we are mapping two variables: one on the y and one on the x.

Link to next slide: for histogram does not make sense to map a second variable on the y, beside count/frequency bcs with a histogram see the total distribution (vs box plot in which you see summary stats of the distribution). 
-->

---

```{r histogram-facet, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = cost)
) +
  geom_histogram() + #BREAK
  facet_wrap(facets = vars(type)) #BREAK
```

`r chunk_reveal(chunk_name = "histogram-facet", break_type = "user", title = "## Multiple windows plot - faceted histogram")`

Multiple windows plot - HISTOGRAM WITH FACETS: looks at **categorical variables**. 

On the y axis is frequency count (calculated from the x). With histograms we cannot map a second variable on the y, but we can use facets to compare the distribution of each college type. Compare with box plot.

---

```{r scatterplot-facet, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(
    x = cost,
    y = netcost
  )
) +
  geom_point() + #BREAK
  facet_wrap(facets = vars(type)) #BREAK
```

`r chunk_reveal(chunk_name = "scatterplot-facet", break_type = "user", title = "## Multiple windows plot - faceted scatterplot")`

Multiple windows plot - SCATTERPLOT WITH FACETS: looks at **continuous variables** (here cost and netcost) and plot each in a separate panel with same scale range on the x and y.

---

```{r scatterplot-mult-channels, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(
    x = cost,
    y = netcost,
    color = type, #ROTATE
    color = type, size = debt #ROTATE
  )
) +
  geom_point()
```

`r chunk_reveal(chunk_name = "scatterplot-mult-channels", break_type = "rotate", font_size_code = "60%", title = "## Utilizing additional aesthetics")`

Additional info: rather than using facets to sort each distribution, we could use the color aesthetic to automatically incorporate the `type` info into the same visualization.

We can also add a fourth variable such as `depth` and render it through the size aesthetic. However, does adding `depth` make the graph more informative? 


---

class: inverse, middle

# Factors

---

Categorical variables, also called discrete variables, are variables that have a fixed set of possible values. R uses **factors** to work these variables.

[**Chapter 15 of R for Data Science**](https://r4ds.had.co.nz/factors.html) goes in-depth on creating and modifying factors: 

```{r create-string, eval = FALSE}
month_string <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun", 
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)
month_string
typeof(month_string)  # character
class(month_string)   # character
```

```{r turn-into-factor, eval = FALSE}
month_factor <- factor(month_string, levels = month_string)
month_factor
typeof(month_factor)  # integer
class(month_factor)   # factor
```

* `class`: attribute of the object, regardless of R internal storage
* `typeof`: R internal storage of the object

---

class: inverse, middle

# Practice exploring data

---

## Acknowledgments 

The content of these slides is derived in part from Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.