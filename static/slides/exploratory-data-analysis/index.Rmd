---
title: "Exploratory Data Analysis"
author: "MACSS 30500 <br /> University of Chicago"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      highlightStyle: magula
      highlightLines: true
      highlightLanguage: r
      ratio: 16:9
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
# generate CSS file
library(xaringanthemer)
style_duo_accent(
  primary_color = "#011f4b",
  secondary_color = "#bbd6c7",
  inverse_header_color = "#222222",
  black_color = "#222222",
  header_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  text_font_google = xaringanthemer::google_font("Atkinson Hyperlegible"),
  code_font_google = xaringanthemer::google_font("Source Code Pro"),
  base_font_size = "24px",
  code_font_size = "20px",
  # title_slide_background_image = "https://github.com/uc-dataviz/course-notes/raw/main/images/hexsticker.svg",
  # title_slide_background_size = "contain",
  # title_slide_background_position = "top",
  header_h1_font_size = "2rem",
  header_h2_font_size = "1.75rem",
  header_h3_font_size = "1.5rem",
  extra_css = list(
    "h1" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h2" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    "h3" = list(
      "margin-block-start" = "0.4rem",
      "margin-block-end" = "0.4rem"
    ),
    ".tiny" = list("font-size" = "70%"),
    ".small" = list("font-size" = "90%"),
    ".midi" = list("font-size" = "150%"),
    ".tiny .remark-code" = list("font-size" = "70%"),
    ".small .remark-code" = list("font-size" = "90%"),
    ".midi .remark-code" = list("font-size" = "150%"),
    ".large" = list("font-size" = "200%"),
    ".xlarge" = list("font-size" = "600%"),
    ".huge" = list(
      "font-size" = "400%",
      "font-family" = "'Montserrat', sans-serif",
      "font-weight" = "bold"
    ),
    ".hand" = list(
      "font-family" = "'Gochi Hand', cursive",
      "font-size" = "125%"
    ),
    ".task" = list(
      "padding-right" = "10px",
      "padding-left" = "10px",
      "padding-top" = "3px",
      "padding-bottom" = "3px",
      "margin-bottom" = "6px",
      "margin-top" = "6px",
      "border-left" = "solid 5px #F1DE67",
      "background-color" = "#F3D03E"
    ),
    ".pull-left" = list(
      "width" = "49%",
      "float" = "left"
    ),
    ".pull-right" = list(
      "width" = "49%",
      "float" = "right"
    ),
    ".pull-left-wide" = list(
      "width" = "70%",
      "float" = "left"
    ),
    ".pull-right-narrow" = list(
      "width" = "27%",
      "float" = "right"
    ),
    ".pull-left-narrow" = list(
      "width" = "27%",
      "float" = "left"
    ),
    ".pull-right-wide" = list(
      "width" = "70%",
      "float" = "right"
    ),
    ".blue" = list(color = "#2A9BB7"),
    ".purple" = list(color = "#a493ba"),
    ".yellow" = list(color = "#f1de67"),
    ".gray" = list(color = "#222222")
  )
)

source(here::here("R", "slide-opts.R"))

# enable panelsets and default theme
xaringanExtra::use_panelset()
```

```{r pkgs, include = FALSE, cache = FALSE}
library(tidyverse)
library(palmerpenguins)
library(rcis)
library(knitr)
library(patchwork)
library(flipbookr)

set.seed(1234)
theme_set(theme_gray(base_size = 16))
```

class: inverse, middle

# Exploratory Data Analysis (EDA)

---

## Definition of Exploratory Data Analysis (EDA)

#### All set of INITIAL investigations in order to get a sense of your data and generate questions: 

+ discovering patterns 
+ spot anomalies (outliers)
+ generate and refine questions 
+ check initial hypotheses before formally testing them

EDA is different from **Explanatory or Confirmatory Data Analysis**

---

## EDA as iterative and creative process

Chapter 7 of "R for Data Science" defines EDA as an **ITERATIVE process**:

1. Generate questions about your data
1. Search for answers in the data by transforming, visualizing, and modeling the data
1. Use what you learn to refine your questions and/or generate new questions
1. Repeat until necessary

--

EDA is a **CREATIVE process**: it is not an exact science. It requires knowledge of your data and time. At the most basic level, it involves answering two questions:

1. What type of variation occurs within my variables?
2. What type of covariation occurs between my variables?


---

## How to perform Exploratory Data Analysis?


EDA relies on:
- **visualizations** such box plots, histograms, bar charts, scatter plots, etc. 
- **descriptive stats** such as measures of central tendency (mean, mode, median) and of dispersion (variance, standard deviation)

--

We focus on visualizations, and especially on:
- Variation: how values within a single variable vary (univariate analysis)
- Covariation: how values of two variables co-vary (bivariate analysis)

--

> Visualizations are employed in both Exploratory and Confirmatory Data Analysis, but their use is different. 

<!--
In Exploratory Analysis you might generate 100 or even 1000 graphs, but not all of them will be useful for your research. In Confirmatory Analysis, you generate only a few graphs and each graph is well refined.
-->

---

class: inverse, middle

# Exploratory and Confirmatory Data Analysis

---

## Comparing Exploratory and Confirmatory plots

```{r}
library(palmerpenguins)
data("penguins")

head(penguins)
```

We want build a plot of two continuous variables: penguins body mass (in grams) and penguins flipper length (in millimeters)

---

```{r penguins-eda, include = FALSE}
ggplot(
  data = penguins,
  mapping = aes(
    x = body_mass_g,
    y = flipper_length_mm
  )
) +
  geom_point() +
  geom_smooth()
```

`r chunk_reveal(chunk_name = "penguins-eda", break_type = "auto", title = "## Exploratory plot")`

Exploratory plot. What does this graph tell us? Pros and cons?

--

Pros: minimum code, easy to replicate, good for your internal use
Cons: not well refined, not good for publication or external audience

How can we improve this graph?

---

```{r penguins-final, include = FALSE}
ggplot(
  data = penguins,
  mapping = aes(
    x = body_mass_g,
    y = flipper_length_mm
  )
) +
  geom_point(alpha = .1) +
  geom_smooth(method = "lm", 
              se = FALSE) +
  labs(
    title = "Relationship between body mass and\nflipper length of a penguin",
    subtitle = "Sample of 344 penguins",
    x = "Body mass (g)",
    y = "Flipper length (mm)"
  ) +
  theme_xaringan(
    title_font_size = 18,
    text_font_size = 16
  )
```

`r chunk_reveal(chunk_name = "penguins-final", break_type = "auto", title = "## Confirmatory plot")`

---

### Bottom line:

The initial plot was created for exploratory purposes. We might generate several of them to explore the data. 

The last plot was created for confirmatory purposes. We start from an exploratory plot and refine it with more code. Use it for a final report, class presentation, paper, final submission of HW2 for this course, etc.

--

Note: difference between `labs()` and `geom_text()` https://ggplot2-book.org/annotations.html


```{r include = FALSE}
# restore default colors
theme_xaringan_restore_defaults()
```

---

class: inverse, middle

# EDA with the `scorecard` dataset

The Department of Education collects annual statistics on colleges and universities in the United States. We are going to look at a subset of this data from 2018-19.

---

## `scorecard`

```{r}
library(tidyverse)
library(rcis)
data("scorecard")
glimpse(scorecard)
```

---

## Types of visualization we can perform

#### *Variation* -- how values within a single variable vary (univariate analysis)
  
* continuous variable: histogram
* categorical variable: bar chart


#### *Covariation* -- how values of two variables co-vary (bivariate analysis)

* continuous variables: scatter plot
* categorical variables: compute count for each, then visualize
* categorical and continuous variables: box plot

---

class: inverse, middle

# Variation: univariate analysis

---

```{r histogram, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = cost)
) +
  geom_histogram()
```

`r chunk_reveal(chunk_name = "histogram", title = "## Histogram")`

HISTOGRAM: for **continuous variables** (here cost). It splits the input variable into n sets of equal width and does a frequency count within each set.

--

What does this histogram tell us?

--

Follow up questions we might ask: Why do we have these different picks? Are there outliers?

---

```{r histogram-bins, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = cost)
) +
  geom_histogram(bins = 50) + #ROTATE
  geom_histogram(bins = 30) + #ROTATE
  geom_histogram(bins = 10) #ROTATE
```

`r chunk_reveal(chunk_name = "histogram-bins", break_type = "rotate", title = "## Histogram")`

Bins: each bar is a bin and represents one interval or set of data. In these examples, we divided the data into 50, 30 (default), or 10 `bins` or equally sized bars. 

Instead than `bins` you can also use `binwidth` (see [here](https://r-charts.com/distribution/histogram-binwidth-ggplot2/))

---

```{r barplot, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = type)
) +
  geom_bar()
```

`r chunk_reveal(chunk_name = "barplot",  title = "## Bar chart")`

BAR CHART: for **categorical variables** (here type). It takes each category of the variable and automatically applies a frequency count to aggregate the data by variable. 

---

## Bar chart 

```{r barplot2, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = type)
) +
  geom_bar()
```

The default stats for `geom_bar()` is `count`. See [documentation](https://ggplot2.tidyverse.org/reference/geom_bar.html) for more.

It means that under the hood `geom_bar()` performs the equivalent of the following:

```{r}
scorecard %>%
  count(type)
```

Unless we explicitly tell `geom_bar()` not to do so by specifying `geom_bar(stats = "identity")`

---

## Reorder bar chart levels

.panelset[
.panel[.panel-name[Not Ordered]


```{r not-ordered, echo = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = type)
) +
  geom_bar()
```

]

.panel[.panel-name[Ordered]

```{r reordered, echo = FALSE}
count_type <- scorecard %>% 
  count(type)

ggplot(count_type,
       mapping = aes(x = reorder(type, desc(n)), 
                     y = n)) +
       geom_bar(stat = "identity")
```

]
]

---

## Reorder bar chart levels

The most straightforward approach to reorder the levels of a categorical variables is with dplyr and ggplot combined:


```
# calculate count for variable of interest and save in new dataframe
count_type <- scorecard %>%
  count(type)

# use the new dataframe to create the graph
ggplot(count_type,
       mapping = aes(x = reorder(type, desc(n)), 
                     y = n)) +
       geom_bar(stat = "identity")
```

--

```
# another way to code this
scorecard %>%
  count(type) %>%
  ggplot(mapping = aes(x = reorder(type, desc(n)), 
                       y = n)) +
  geom_bar(stat = "identity")
```


---

## Reorder bar chart levels

[`fct_relevel()`](https://forcats.tidyverse.org/reference/fct_relevel.html): allows to reorder factor levels by hand

```
scorecard %>%
  mutate(
  type = fct_relevel(.f = type, 
                    levels = "Private, nonprofit", "Public", "Private, for-profit" )) %>%
  ggplot(
    mapping = aes(x = type)) +
    geom_bar()
```

[`fct_infreq()`](https://forcats.tidyverse.org/reference/fct_inorder.html): reorders factor levels by the number of obs. with each level (e.g., by frequency)

```
scorecard %>%
  mutate(type = fct_infreq(type)) %>%
  ggplot(
    mapping = aes(x = type)) +
  geom_bar()
```

---

## Other types of univariate and bivariate graphs

See the Visualization cheat sheet! 

Help > Cheat Sheets > Data Visualization with ggplot2

Note there are several **cheat sheets** for tidyverse and R: https://posit.co/resources/cheatsheets/

---

class: inverse, middle

# Covariation: bivariate analysis

---

## Covariation

1. Two-dimensional graphs
1. Multiple window plots
1. Utilizing additional channels

---

```{r boxplot, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(
    x = type,
    y = cost
  )
) +
  geom_boxplot()
```

`r chunk_reveal(chunk_name = "boxplot", title = "## Box plot")`

BOX PLOT: looks at the relationship between a **continuous variable** (here cost) and a  **categorical variable** (here type). It summarizes the continuous variable distribution across each of the categorical variables.

--

What does this box plot tell us?

<!-- median is the line in the middle, the middle value 
Here we see that on average, public universities are the least expensive, followed by private for-profit institutions. I was somewhat surprised by this since for-profit institutions by definition seek to generate a profit, so wouldn't they be the most expensive? But perhaps this makes sense, because they have to attract students so need to offer a better financial value than competing nonprofit or public institutions. Is there a better explanation for these differences? Another question you could explore after viewing this visualization.
-->

---

## Box plot

```{r echo = FALSE}
include_graphics(path = "https://d33wubrfki0l68.cloudfront.net/153b9af53b33918353fda9b691ded68cd7f62f51/5b616/images/eda-boxplot.png")
```

.footnote[Source of image: R for Data Science Chapter 7]


---

```{r scatterplot, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(
    x = cost,
    y = netcost
  )
) +
  geom_point()
```

`r chunk_reveal(chunk_name = "scatterplot", title = "## Scatterplot")`

SCATTERPLOT: looks at the relationship between two **continuous variables** (here cost and netcost). 


--

What does this scatterplot tell us?

<!--

As the advertised price increases, the net cost also increases though with significant variations. Some schools have a much lower net cost than their advertised price.

No clear alignment on diagonal, net costs tend to be lower than adv costs for several schools, especially as the adv costs increase; in most universities the average student pay less than the adv costs. Notice this is a 2d plot bcs we are mapping two variables: one on the y and one on the x.

Link to next slide: for histogram does not make sense to map a second variable on the y, beside count/frequency bcs with a histogram see the total distribution (vs box plot in which you see summary stats of the distribution). 
-->

---

```{r histogram-facet, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(x = cost)
) +
  geom_histogram() + #BREAK
  facet_wrap(facets = vars(type)) #BREAK
```

`r chunk_reveal(chunk_name = "histogram-facet", break_type = "user", title = "## Multiple windows plot - faceted histogram")`

HISTOGRAM WITH FACETS: looks at the distribution of a continuous variable (here cost) for several categories (here types of school). 

On the y axis is frequency count for each categorical variable. With histograms we cannot map a second variable, but we can use facets to compare the distribution of each college type. Compare this with box plot.

---

```{r scatterplot-facet, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(
    x = cost,
    y = netcost
  )
) +
  geom_point() + #BREAK
  facet_wrap(facets = vars(type)) #BREAK
```

`r chunk_reveal(chunk_name = "scatterplot-facet", break_type = "user", title = "## Multiple windows plot - faceted scatterplot")`

SCATTERPLOT WITH FACETS: looks at two  **continuous variables** (here cost and netcost) for several categories (here types of school), and plot each in a separate panel with same scale range on the x and y.

---

```{r scatterplot-mult-channels, include = FALSE}
ggplot(
  data = scorecard,
  mapping = aes(
    x = cost,
    y = netcost,
    color = type, #ROTATE
    color = type, size = debt #ROTATE
  )
) +
  geom_point()
```

`r chunk_reveal(chunk_name = "scatterplot-mult-channels", break_type = "rotate", font_size_code = "60%", title = "## Utilizing additional aesthetics")`

Rather than using facets (for the school type), we could use the color aesthetic to automatically incorporate the `type` info into the same visualization.

We can also add a fourth variable such as `depth` and render it through the size aesthetic. But does adding `depth` make the graph more informative? 


---

class: inverse, middle

# Factors

---

Categorical variables, also called discrete variables: variables that have a fixed set of possible values. R uses **factors** to work with these variables.

[**Chapter 15 of R for Data Science**](https://r4ds.had.co.nz/factors.html) goes in-depth on creating and modifying factors: 

```{r create-string, eval = FALSE}
month_string <- c(
  "Jan", "Feb", "Mar", "Apr", "May", "Jun", 
  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
)
month_string
class(month_string)   # character
```

```{r turn-into-factor, eval = FALSE}
month_factor <- factor(month_string, levels = month_string)
month_factor
class(month_factor)   # factor
```

Notice `class` is the attribute of the object (vs `typeof`: R internal storage of the object)

---

class: inverse, middle

# Practice exploring data

Download today's class material from the website 
---

## Acknowledgments 

The content of these slides is derived in part from Benjamin Soltoff’s “Computing for the Social Sciences” course materials, licensed under the CC BY NC 4.0 Creative Commons License. Any errors or oversights are mine alone.