<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Getting data from the web: scraping</title>
    <meta charset="utf-8" />
    <meta name="author" content="MACSS 30500   University of Chicago" />
    <script src="index_files/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Getting data from the web: scraping
]
.author[
### MACSS 30500 <br /> University of Chicago
]

---






class: inverse, middle

# Agenda

* Web Scraping Intro: 
  * Definition
  * Two ways to scrape data from the web: directly or via API

* Two Key Concepts:
  * How the web works
  * What is behind a website

+ Direct scraping in R with `rvest`

---

class: inverse, middle

## Web Scraping Intro

---

## What is web scraping?


**Web scraping is the process of collecting information from a website.** If you've ever copied and pasted info from the Internet, you've done the same task as a scraper, just manually and on a small scale. Web scraping automates and scales up this process!

**Examples:**

* companies' names, emails, and phone numbers 
* newspaper articles 
* products' prices, descriptions, and characteristics 
* real estate data
* social media (comments, likes, followers, customer reviews, etc.)
* selling or exchange of goods websites (craigslist, etc.)
* forums
* etc.

---

&lt;img src="webscraping.png" width="70%" style="display: block; margin: auto;" /&gt;

Image Source at [this link](https://medium.com/analytics-vidhya/web-scraping-in-python-for-data-analysis-6bf355e4fdc8)

---

## Two ways to scrape data from the web

&lt;br&gt;

### 1. Directly scraping the website

* Every website is built with code, typically a mix of HTML, CSS, and JavaScript.
* To collect data from a website, we need to learn how to interact with this code.
* Example: in theory, anything! in practice, start simple like Wikipedia or government sites.


--

### 2. Using a web API (Application Programming Interface)

* Interface provided by the website that allows users to collect data from it.
* To collect data from a website using an API, you need to learn how to use that API.
* Example: [OMDb API](https://omdbapi.com/), see chapter 4 from today's readings.

---

## Our plan

**Today** we focus on directly scraping websites: 
* we cover some theory and key concepts
* we practice!

**Next lecture** we focus on scraping using APIs.


---

class: inverse, middle

## Two Key Concepts...

&lt;!--
1.  **How the web works** (e.g., how computers interact with each other on the web)

1.  **What is behind a website** (e.g., the code websites are made of)
--&gt;

---

class: inverse, middle

## Concept 1: How the web works

---

### How do computer interact on the web? Theory

Computers communicate on the web by sending and receiving **data requests** (GET) and **data responses** (POST). Every computer has an address that other computers can refer to.

When you click on a webpage, your **web browser** (e.g., Chrome, Safari) sends a data request to the **web server** of that page (a database where all the info about that page are stored) and receives a response.

&lt;img src="request_response.png" width="50%" style="display: block; margin: auto;" /&gt;

Image Source [at this link](https://www.linkedin.com/pulse/what-happens-when-you-enter-url-browser-he-asked-victor-ohachor)

---

### How do computer interact on the web? Example

Navigating the web basically means **sending requests to different servers and receiving back various files**, mainly written in HTML and other languages.

For example, if you type `https://macss.uchicago.edu/current-student-resources` into your web browser and hit enter, these steps occur behind the scenes:

1. your web browser (Chrome, Safari, etc.) translates what you typed into a HTTP request. That request tells the web server that stores all `macss` info that you want to access the specific piece of info stored at `/current-student-resources`

1. the web server that hosts `macss` receives your request and sends back to your web browser an response and the response content (a bunch of files written in HTML)

1. your browser transforms the response content into a nice visual display that might include texts, graphics, hyperlinks, etc.

--

**When we scrape data, we use R packages that perform these steps for us (via APIs or without)!**

---

class: inverse, middle

## Concept 2: What is behind a website

---

### What is behind a website

A website is made of the following elements:

+ **HTML**, which means *HyperText Markup Language*, is the core element of a website. HTML uses tags to organize the webpage (i.e., makes the text bold, creates paragraphs, inserts hyperlinks, etc.), but when the page is displayed the markup language is hidden

+ **CSS**, which means *Cascading Style Sheets*: to make the page looks nice

+ **Javascript (JS)** code: to add interactive elements to the page (you need "dynamic web scraping" techniques to scrape JS code, not covered in this course)

+ **Other stuff** such as images, hyperlinks, videos or multimedia

---

### What is behind a website

Knowing how read the HTML (and CSS) language, is fundamental when we crape the website directly. When we use an API and/or an API wrapper, this is less important, but still useful. 

Our goal: lean how to read HTML and CSS languages

---

### HTML: HyperText Markup Language

* most important thing for web scraping: makes the "skeleton" or structure of a website
* it is made of tags 
* looks messy, but follows a hierarchical [tree-like structure](https://www.researchgate.net/figure/HTML-source-code-represented-as-tree-structure_fig10_266611108) of tags within tags 

Standard HTML syntax:
```
   &lt;html&gt;
     &lt;head&gt;
        &lt;title&gt;general info about the page&lt;/title&gt;
     &lt;/head&gt;
     &lt;body&gt;
       &lt;p&gt;a paragraph with some text about the page&lt;/p&gt;
       &lt;p&gt;another paragraph with more text&lt;/p&gt;
       &lt;p&gt;ciao&lt;/p&gt;
     &lt;/body&gt;
   &lt;/html&gt;
   
```

---

### HTML Tags

* tags are organized in a **tree-like structure** and are nested within each other

* tags **go in pairs** one on each end of the content that they display: 
   * example: `&lt;p&gt;ciao&lt;/p&gt;` only the word "ciao" shows up on the webpage, and the `/` signals the end of the tag

* tags can have **attributes** which provide more info: 
    * example: `&lt;p&gt;ciao id='first'&lt;/p&gt;`
    * there are two important attributes for scraping: `id` and `class`; these two HTML attributes are used together with CSS elements to control the visual appearance of the page
    
--

Let's examine the HMTL tags structure more closely!

&lt;!-- add more info here
https://plsc-31101.github.io/course/collecting-data-from-the-web.html#webscraping
* more frequently used tags
* more on tags attributes
* CSS 
* CSS and HTML
* see staff from my Python course, lecture 2 (e.g. every page is different, no perfect structure,etc.)
--&gt;

---

### HTML Tags

* `html`
    * `head`
        * `title`
        * `a href`
        * `script`
    * `body`
        * `div`
            * `p`
                * `b`
            * `span`
        * `table`
            * `tr`
                * `td`
                * `td`
        * `img`

---

### HTML Tags

* `html`
    * `head`
        * `title`
        * `a href` -- links
        * `script` -- code
    * `body`
        * `div` -- generic container for content (block)
            * `p` -- paragraph
                * `b` -- bold formatting
            * `span` -- generic container for content (in line)
        * `table`
            * `tr` -- row of cells
                * `td` -- actual cell element 
                * `td`
        * `img`


---

### HTML Tags: example

.small[
```html
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Title&lt;/title&gt;
    &lt;a href="http://github.com"&gt;GitHub&lt;/a&gt;
    &lt;script src="https://c.js"&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div&gt;
      &lt;p&gt;Click &lt;b&gt;here&lt;/b&gt; now.&lt;/p&gt;
      &lt;span&gt;Frozen&lt;/span&gt;
    &lt;/div&gt;
    &lt;table style="width:100%"&gt;
      &lt;tr&gt;
        &lt;td&gt;Kristen&lt;/td&gt;
        &lt;td&gt;Bell&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/table&gt;
  &lt;img src="http://ia.media-imdb.com/images.png"/&gt;
  &lt;/body&gt;
&lt;/html&gt;
```
]
Find: (1) the text content `Frozen`; (2) the GitHub link and the text content `GitHub`

---

### HTML Tags: example

**Find the text content `Frozen`:**

--

```html
&lt;span&gt;Frozen&lt;/span&gt;
```

* `&lt;span&gt;&lt;/span&gt;` - tag name
* `Frozen` - content as text

&lt;!--In this ex. there is only one span tag: what if the HTML has multiple span tags?--&gt;

--

**Find the GitHub link and text content `GitHub`:**

--

```html
&lt;a href="http://github.com"&gt;GitHub&lt;/a&gt;
```

* `&lt;a&gt;&lt;/a&gt;` - tag name
* `href` - tag attribute (argument)
* `"http://github.com"` - tag attribute (value)
* `GitHub` - content as text

---

### CSS: Cascading Style Sheet

Often a website has HTML tags (with attributes) and CSS elements:
* **HTML defines the content** 
* **CSS defines the format** 

This is an example of CSS code. Notice: (1) it is different from HTML code; and (2) the `span` HTML tag can be styled using CSS `color`: 

```css
span {
  color: #ffffff; }
```
--

**Most websites use HTML tags with `class` and `id` attributes to provide “hooks” for CSS elements**. This way the CSS "knows" where to apply CSS stylistic elements.

Example: https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/class

&lt;!-- https://plsc-31101.github.io/course/collecting-data-from-the-web.html#webscraping 
[CSS diner](http://flukeout.github.io) 

### HTML + CSS: example 

.pull-left[

```html
&lt;body&gt;
    &lt;table id="content"&gt;
        &lt;tr class='name'&gt;
            &lt;td class='firstname'&gt;
                Kurtis
            &lt;/td&gt;
            &lt;td class='lastname'&gt;
                McCoy
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr class='name'&gt;
            &lt;td class='firstname'&gt;
                Leah
            &lt;/td&gt;
            &lt;td class='lastname'&gt;
                Guerrero
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/table&gt;
&lt;/body&gt;
```

]

.pull-right[

Find the elements to use to extract:
1. The entire table
1. The general element(s) containing first names
1. Just the specific element "Kurtis"

]

--&gt;

---

### HTML + CSS: further resources

* Great intro guide: `rvest` page "Web scraping 101" https://rvest.tidyverse.org/articles/rvest.html

* Using HTML and CSS for scraping: https://sscc.wisc.edu/sscc/pubs/webscraping-r/html.html

* Handy references for your scraping projects:

  * HTML overview: https://www.w3schools.com/html/html_intro.asp
  * List of tags: https://developer.mozilla.org/en-US/docs/Web/HTML/Element 

* See our website (today's lecture) for more!

---

class: inverse, middle

## Practice all of this in R with the `rvest` package

* `rvest`: https://rvest.tidyverse.org/ 
* Example: scraping presidential statements

---

### Using `rvest` to read HTML

**The R package [`rvest`](`https://rvest.tidyverse.org/`) allows us to:**
1. Collect and read the HTML source code of a webpage
1. Find and keep the specific HTLM/CSS elements that we want from that webpage using HTML tags or attributes, and using CSS selectors

--

**Our Example: Presidential statements**

We are going to scrape data from this URL: `https://www.presidency.ucsb.edu/documents/special-message-the-congress-relative-space-science-and-exploration`

Download today's class materials to follow along!

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
