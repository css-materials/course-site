<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Importing data and data cleaning</title>
    <meta charset="utf-8" />
    <meta name="author" content="MACSS 30500   University of Chicago" />
    <script src="index_files/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Importing data and data cleaning
]
.author[
### MACSS 30500 <br /> University of Chicago
]

---







class: inverse, middle

## Agenda

* Finish reviewing dplyr “verbs”: see lecture 5 in-class materials 

* Data cleaning: 
  * renaming and recording variables + syntactic and non-syntactic variable names
  * improve bar chart from lecture 4 (EDA)
  
* Importing and exporting data in R

---

class: inverse, middle

## Data cleaning

We talk about data cleaning (renaming and recording variables + syntactic and non-syntactic variable names)  using the `.Rmd` tutorial, available in today's in-class materials on the website.

In today's materials, you will also find another `.Rmd` tutorial with code to improve the bar chart from lecture 4 (Exploratory Data Analysis), using what we have learned so far about data transformation, cleaning, and plotting.

---

class: inverse, middle

## Importing and Exporting Data into R with `readr`

`readr` documentation: https://readr.tidyverse.org/

---

### Importing CSV files

To load data into R we need **importing functions**. There are a number of them depending on the **type of file** we want to import (see "R for Data Science" 2nd Ed. Ch. 7).

The most common importing functions read **comma-separated values** files. Two main versions:

- from **base-R** we have `read.csv()`

- from **`readr`**, which is part of the `tidyverse`, we have `read_csv()`

--

They are similar, but we use `read_csv()` in this course because is more recent, faster, and does not automatically changes data types (e.g., converts strings into factors)

&lt;!-- `read.csv` is a special case of `read.table`, while `read_csv` is special case of `read_delim`. Look them up to check the differences -- r 
--&gt;

---

## `read_csv()`

It takes several arguments (see [documentation](https://readr.tidyverse.org/reference/read_delim.html)). Most commonly used:

```
read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))
```
--

The `file` argument must specified, the other arguments can be left as default:

```
library(readr)

# load data into my local R Studio
read_csv(file = "/Users/Sabrina Nardin/Desktop/testdata.csv")

# load data into my Workbench 
read_csv(file = "/home/nardin/testdata.csv")

# another way to load data if you are not sure where it is located
read_csv(file = file.choose())
```

&lt;!--
Make sure the file is located in the given path and you are typing the path correctly. Let's practice!
--&gt;

---

### Practice loading data in R

1. Create a `testdata.csv` file with four columns (id, name, age, food) with different data types and some missing data. Save it on your desktop with a `csv` extension.

1. Open Workbench: upload the file to the server. Skip this step if you are using R on your machine.

1. Look at your current working directory by typing `getwd()` in the console. That's where R looks at files by default.

1. Load the `library(tidyverse)` and then load the data into R using the `read_csv()` function. Make sure to specify the correct path. If you do not provide a path, R looks in your working directory. Here are two examples:
 * `read_csv("/Users/Sabrina Nardin/Desktop/testdata.csv")` 
 * `read_csv("testdata.csv")`

---

### Changing defaults: examples

We are going to modify some of the most common arguments of the `read_csv()` function. But first let's use it without modifying them by simply typing `read_csv(file = "testdata.csv")`

What do you notice? 

&lt;!--
This file is a good example of messy data!
type of column is shown at the top, e.g. id is double, name is char, but so is age, which should not be. Why so? the "na" is interpret as a character rather than missing data and all column values are forced to character.
--&gt;

---

### Modify `col_type`

The default is `read_csv(file, col_types = NULL)`. We can change it to manually set the column types:

```
# option 1
read_csv(file = "testdata.csv",
         col_types = cols(id = col_integer(),
                          name = col_character(),
                          age = col_integer(),
                          food = col_character()))
# option 2
read_csv("testdata.csv", col_types = ("icic"))
```

What do you notice?

&lt;!-- all columns types have been converted to the datatype we specified. R is also guessing that the na in age is actually missing data and so converts it as such, but we get a warning message; type problems() to see more
--&gt;

---

### Modify `na`

The default is `read_csv(file, na = c("", "NA"))`. We can change it to add more missing data options:

```
read_csv("testdata.csv", col_types = ("icic"), na = c("", "NA", "na", "None"))
```

What do you notice?

&lt;!-- we can enlarge the set of missing data to include everything we want --&gt;


---

### Modify `col_names`

The default is `read_csv(file, col_names = TRUE)`. We can change it to `col_names = FALSE`.

```
read_csv(file = "testdata.csv", col_names = FALSE)

```

What do you notice?

&lt;!-- first line is not more read as variable names --&gt;

---

### Working directory

The working directory is the folder that R takes as **default directory** every time you try to load a file, script, etc.

To check your current working directory: start a new session of R and type `getwd()`. In Workbench it should be `"/home/your_cnetid"`

---

### Relative vs. Full path

When you import a file (e.g., from Workbench "Files" tab) to R, you want to use so-called "relative path" rather than a so-called "absolute path"

**Relative path:** relative to the project folder where this project is stored. This is the best approach but it works only if the file is located in R default working directory
```
read_csv(file = "testdata.csv")
```

**Absolute path:** specify the full path 
```
read_csv(file = "/home/nardin/testdata.csv")
```

&lt;!--
You can also manually set your directory to an absolute path, for example using `setwd()` but that is not the best approach for reproducible. Use relative paths instead!
--&gt;

---

### RStudio Projects `.Rproj`

R studio has something called "RStudio Projects" (**`.Rproj`**). R will automatically detect the working directory based on your project. 

This ensures portability and a reliable behavior!

--

For example, every homework and in-class exercise folder that we have been using in this course has a `.Rproj` file. This file helps R to automatically detect the working directory. If you switch between projects, the working directory changes automatically. 

&lt;!-- for HW3, released tmr, we are asking to load data, we will be giving you a rproj like in HW2, so all you have to do to load teh data is to be in the correct project and then use a relative path with the name of the data.csv
--&gt;

---

### Other `readr` functions to import data 

The `readr` package include several functions to load into R almost all possible file formats that you might encounter (when given an option though, choose a `csv` over other formats). 

For example:

* **Comma separated csv** use `read_csv()` from the `readr` package
* **Semi column separated csv** use `read_csv2()`from the `readr` package
* **Tab separated files** use `read_tsv()`from the `readr` package
* **RDS** use `readRDS()` or `read_rds()`
* **Excel** use `read_excel()` from the `readxl` package
* **SAS/SPSS/Stata** use the `haven` package (several functions)

--

Cheat Sheet for `readr`:
**Help &gt; Cheat Sheets &gt; Browse Cheat Sheets**

---

### `haven` and SAS


```r
library(haven)

read_sas(data_file = system.file("examples", "iris.sas7bdat",
  package = "haven"
))
```

```
## # A tibble: 150 × 5
##    Sepal_Length Sepal_Width Petal_Length Petal_Width Species
##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  
##  1          5.1         3.5          1.4         0.2 setosa 
##  2          4.9         3            1.4         0.2 setosa 
##  3          4.7         3.2          1.3         0.2 setosa 
##  4          4.6         3.1          1.5         0.2 setosa 
##  5          5           3.6          1.4         0.2 setosa 
##  6          5.4         3.9          1.7         0.4 setosa 
##  7          4.6         3.4          1.4         0.3 setosa 
##  8          5           3.4          1.5         0.2 setosa 
##  9          4.4         2.9          1.4         0.2 setosa 
## 10          4.9         3.1          1.5         0.1 setosa 
## # ℹ 140 more rows
```

---

### `haven` and SPSS


```r
read_sav(file = system.file("examples", "iris.sav",
  package = "haven"
))
```

```
## # A tibble: 150 × 5
##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species   
##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl+lbl&gt; 
##  1          5.1         3.5          1.4         0.2 1 [setosa]
##  2          4.9         3            1.4         0.2 1 [setosa]
##  3          4.7         3.2          1.3         0.2 1 [setosa]
##  4          4.6         3.1          1.5         0.2 1 [setosa]
##  5          5           3.6          1.4         0.2 1 [setosa]
##  6          5.4         3.9          1.7         0.4 1 [setosa]
##  7          4.6         3.4          1.4         0.3 1 [setosa]
##  8          5           3.4          1.5         0.2 1 [setosa]
##  9          4.4         2.9          1.4         0.2 1 [setosa]
## 10          4.9         3.1          1.5         0.1 1 [setosa]
## # ℹ 140 more rows
```

---

### `haven` and Stata


```r
read_dta(file = system.file("examples", "iris.dta",
  package = "haven"
))
```

```
## # A tibble: 150 × 5
##    sepallength sepalwidth petallength petalwidth species
##          &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  
##  1        5.10       3.5         1.40      0.200 setosa 
##  2        4.90       3           1.40      0.200 setosa 
##  3        4.70       3.20        1.30      0.200 setosa 
##  4        4.60       3.10        1.5       0.200 setosa 
##  5        5          3.60        1.40      0.200 setosa 
##  6        5.40       3.90        1.70      0.400 setosa 
##  7        4.60       3.40        1.40      0.300 setosa 
##  8        5          3.40        1.5       0.200 setosa 
##  9        4.40       2.90        1.40      0.200 setosa 
## 10        4.90       3.10        1.5       0.100 setosa 
## # ℹ 140 more rows
```

---

### Exporting Data from R with `write_csv()`

Similarly to the `read_csv()` function for importing data, there is a `write_csv()` function for exporting data. 

**`write_csv()` generates csv files from R data frames**

Documentation: https://readr.tidyverse.org/reference/write_delim.html

```
# import
test &lt;- read_csv("testdata.csv", col_types = ("icic"), na = c("", "NA", "na", "None"))

# export
write_csv(test, file = "testdata_cleaned.csv")
```

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"highlightLanguage": "r",
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
